{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Credit Card Fraud Detection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXBU-HzC9ddd"
      },
      "source": [
        "#STEP 1: IMPORTING PACKAGES\n",
        "\n",
        "import pandas as pd # this package is for data processing\n",
        "import numpy as np #library to work with arrays\n",
        "import matplotlib.pyplot as plt #library to create visualizations in Python\n",
        "import tensorflow as tf #TensorFlow\n",
        "from termcolor import colored as cl #tool for text customization\n",
        "import itertools #library in Python consisting of multiple methods used in iterators\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler #Tool for data normalization/standardization\n",
        "from sklearn.model_selection import train_test_split #function that splits data arrays into 2 subsets: training & testing\n",
        "from sklearn.tree import DecisionTreeClassifier #Decision tree algorithm\n",
        "from sklearn.neighbors import KNeighborsClassifier #algorithm that implements learning based on the k nearest neighbors\n",
        "from sklearn.linear_model import LogisticRegression #Logistic regression algorithm (ML algorithm used to predict the probability of a categorical dependent variable)\n",
        "from sklearn.svm import SVC #Stands for \"Support Vector Classification\", and it's an SVM algorithm\n",
        "from sklearn.ensemble import RandomForestClassifier #Random forest tree algorithm\n",
        "from xgboost import XGBClassifier #Machine Learning Algorithm.\n",
        "\n",
        "from sklearn.metrics import confusion_matrix #evaluation metric\n",
        "from sklearn.metrics import accuracy_score #evaluation metric\n",
        "from sklearn.metrics import f1_score #evaluation metric"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q8OJa3YmIgAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17925EC49_Ez"
      },
      "source": [
        "**Notes:**\n",
        "- Iterators are objects that allow us to iterate over all the elements of a collection and return one element at a time.\n",
        "- When a dataset contains variable that are in different scales, *StandardScaler* performs the task of **Standardization** so they have a common scale.\n",
        "- **Support Vector Machines** are supervised learning methods used for classification.\n",
        "- **Random Forest Classifier** creates a set of decision trees from a random subset of the training set.\n",
        "- **XGBoost** is an implementation of gradient boosted decision trees designed for speed and performance.\n",
        "- A **Confusion Matrix** is a summary of prediction results on a classification problem.\n",
        "- Accuracy is simply a ratio of correctly predicted observations to the total observations.\n",
        "- Also known as F-score, the **F1 Score** is a weighted average of the precision and recall score. Used as an evaluation metric, a high F-score is a sign of a well-performing model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "ougfKzMR-EHZ",
        "outputId": "f270a5d1-2239-476a-ecca-aed56e69fd32"
      },
      "source": [
        "#Now I'm going to import my data from the Kaggle dataset which I have previously downloaded to my computer from\n",
        "#the following website:\n",
        "\n",
        "#kaggle dataset: https://www.kaggle.com/mlg-ulb/creditcardfraud\n",
        "\n",
        "\n",
        "from google.colab import files #On Nov 28 I introduced these two lines of code and it was one of the best decisions.\n",
        "uploaded = files.upload() #This creates a widget prompting the user to browse for a file and uploads it to files inside Colab.\n",
        "df = pd.read_csv('../../Downloads/creditcard.csv')\n",
        "df.drop('Time', axis = 1, inplace = True)\n",
        "df.head"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-115e896d-c345-4dd8-9f2e-348bfbba20f2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-115e896d-c345-4dd8-9f2e-348bfbba20f2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jQRiwaRXKqG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24626e8e-20fa-4b79-db99-56f13416b2f1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHfDAc-X7oiV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac874ef9-3b58-4585-efe7-aa47d6f5bf80"
      },
      "source": [
        "cases = len(df)\n",
        "nonfraud_count = len(df[df.Class == 0])\n",
        "fraud_count = len(df[df.Class == 1])\n",
        "fraud_percentage = round(fraud_count/nonfraud_count*100, 2)\n",
        "\n",
        "print(cl('CASE COUNT', attrs = ['bold']))\n",
        "print(cl('--------------------------------------------------', attrs= ['bold']))\n",
        "print(cl('Total number of cases are {}'.format(cases), attrs = ['bold']))\n",
        "print(cl('Number of Non-fraud cases are {}'.format(nonfraud_count), attrs = ['bold']))\n",
        "print(cl('Percentage of fraud cases is {}'.format(fraud_percentage), attrs = ['bold']))\n",
        "print(cl('--------------------------------------------------', attrs = ['bold']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mCASE COUNT\u001b[0m\n",
            "\u001b[1m--------------------------------------------------\u001b[0m\n",
            "\u001b[1mTotal number of cases are 284807\u001b[0m\n",
            "\u001b[1mNumber of Non-fraud cases are 284315\u001b[0m\n",
            "\u001b[1mPercentage of fraud cases is 0.17\u001b[0m\n",
            "\u001b[1m--------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kH31BA4n31g"
      },
      "source": [
        "**Notes:**\n",
        "- When working with the **print statement** I am wondering... *What does the \"cl\" stand for?*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3G8VpVzptYN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "076703ba-f8fb-4702-c339-0e94370dd925"
      },
      "source": [
        "nonfraud_cases = df[df.Class == 0]\n",
        "fraud_cases = df[df.Class == 1]\n",
        "\n",
        "#What are we doing here? Are we creating a class or some sort\n",
        "#of boolean?\n",
        "\n",
        "print(cl('CASE AMOUNT STATISTICS', attrs = ['bold']))\n",
        "print(cl('--------------------------------------------------', attrs= ['bold']))\n",
        "print(cl('NON-FRAUD CASE AMOUNT STATS', attrs= ['bold']))\n",
        "print(nonfraud_cases.Amount.describe())\n",
        "print(cl('--------------------------------------------------', attrs= ['bold']))\n",
        "print(cl('FRAUD CASE AMOUNT STATS', attrs= ['bold']))\n",
        "print(fraud_cases.Amount.describe())\n",
        "print(cl('--------------------------------------------------', attrs= ['bold']))\n",
        "\n",
        "#I think what this is doing is to call the describe function\n",
        "#with amounts. But what does *.amount* do?"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mCASE AMOUNT STATISTICS\u001b[0m\n",
            "\u001b[1m--------------------------------------------------\u001b[0m\n",
            "\u001b[1mNON-FRAUD CASE AMOUNT STATS\u001b[0m\n",
            "count    284315.000000\n",
            "mean         88.291022\n",
            "std         250.105092\n",
            "min           0.000000\n",
            "25%           5.650000\n",
            "50%          22.000000\n",
            "75%          77.050000\n",
            "max       25691.160000\n",
            "Name: Amount, dtype: float64\n",
            "\u001b[1m--------------------------------------------------\u001b[0m\n",
            "\u001b[1mFRAUD CASE AMOUNT STATS\u001b[0m\n",
            "count     492.000000\n",
            "mean      122.211321\n",
            "std       256.683288\n",
            "min         0.000000\n",
            "25%         1.000000\n",
            "50%         9.250000\n",
            "75%       105.890000\n",
            "max      2125.870000\n",
            "Name: Amount, dtype: float64\n",
            "\u001b[1m--------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUT5RwQ6tiqM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bd7d2a8-0965-42ff-f74b-7862117f4543"
      },
      "source": [
        "#Now we are going to normalize our data because we need to\n",
        "#reduce the wide range of values in the \"Amount\" variable to\n",
        "#a smaller scale so we can work better.\n",
        "\n",
        "sc = StandardScaler()\n",
        "amount = df['Amount'].values\n",
        "\n",
        "df['Amount'] = sc.fit_transform(amount.reshape(-1, 1))\n",
        "\n",
        "print(cl(df['Amount'].head(10), attrs = ['bold']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m0    0.244964\n",
            "1   -0.342475\n",
            "2    1.160686\n",
            "3    0.140534\n",
            "4   -0.073403\n",
            "5   -0.338556\n",
            "6   -0.333279\n",
            "7   -0.190107\n",
            "8    0.019392\n",
            "9   -0.338516\n",
            "Name: Amount, dtype: float64\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRmzsIfhCzOb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ad4f248-246a-4c6b-a1b0-95dbf368b4b1"
      },
      "source": [
        "# DATA SPLIT\n",
        "#Defining the independent and dependent variables.\n",
        "\n",
        "X = df.drop('Class', axis = 1).values\n",
        "y = df['Class'].values\n",
        "\n",
        "#What does this line of code below mean?\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
        "\n",
        "print(cl('X_train samples : ', attrs= ['bold']), X_train[:1])\n",
        "print(cl('X_test samples : ', attrs= ['bold']), X_test[0:1])\n",
        "print(cl('y_train samples : ', attrs=['bold']), y_train[0:20])\n",
        "print(cl('y_test samples: ', attrs = ['bold']), y_test[0:20])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mX_train samples : \u001b[0m [[-1.11504743  1.03558276  0.80071244 -1.06039825  0.03262117  0.85342216\n",
            "  -0.61424348 -3.23116112  1.53994798 -0.81690879 -1.30559201  0.1081772\n",
            "  -0.85960958 -0.07193421  0.90665563 -1.72092961  0.79785322 -0.0067594\n",
            "   1.95677806 -0.64489556  3.02038533 -0.53961798  0.03315649 -0.77494577\n",
            "   0.10586781 -0.43085348  0.22973694 -0.0705913  -0.30145418]]\n",
            "\u001b[1mX_test samples : \u001b[0m [[-0.32333357  1.05745525 -0.04834115 -0.60720431  1.25982115 -0.09176072\n",
            "   1.1591015  -0.12433461 -0.17463954 -1.64440065 -1.11886302  0.20264731\n",
            "   1.14596495 -1.80235956 -0.24717793 -0.06094535  0.84660574  0.37945439\n",
            "   0.84726224  0.18640942 -0.20709827 -0.43389027 -0.26161328 -0.04665061\n",
            "   0.2115123   0.00829721  0.10849443  0.16113917 -0.19330595]]\n",
            "\u001b[1my_train samples : \u001b[0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "\u001b[1my_test samples: \u001b[0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzNlL5s7E3am"
      },
      "source": [
        "We have all the required components to build our classification models, which is our next step.\n",
        "\n",
        "# **Building the Model**\n",
        "\n",
        "For this project we will build 6 different types of classification models using algorithms by scikit-learn.\n",
        "\n",
        "1. Decision Tree\n",
        "2. K-Nearest Neighbors (KNN)\n",
        "3. Logistic Regression\n",
        "4. Support Vector Machine (SVM)\n",
        "5. Random Forest\n",
        "6. XGBoost\n",
        "\n",
        "# **Evaluation Metrics for Classification Models**\n",
        "\n",
        "We will use the following metrics to evaluate the models and decide which one is the best#\n",
        "\n",
        "+ Accuracy Score\n",
        "+ F1 Score\n",
        "+ Confusion Matrix\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUNPbgFctThU"
      },
      "source": [
        "# Models\n",
        "\n",
        "# 1. Decision Tree\n",
        "\n",
        "#When max_depth = 4 we allow the tree to split four times\n",
        "#Criterion is a parameter that measures the quality of a split\n",
        "#in our decision trees. \"Gini Index\" & \"Entropy\" are two\n",
        "#different measures of impurity or disorder*?\n",
        "tree_model = DecisionTreeClassifier(max_depth = 4, criterion = 'entropy')\n",
        "tree_model.fit(X_train, y_train)\n",
        "tree_yhat = tree_model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i55Ts6EeyTdi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c98e6b5-f3a8-4a1a-ecd3-9986b6968187"
      },
      "source": [
        "#Let's print the evaluation metrics for this model.\n",
        "\n",
        "# 1. Accuracy score\n",
        "\n",
        "print(cl('ACCURACY SCORE', attrs = ['bold']))\n",
        "print(cl('------------------------------------------------------------------------', attrs = ['bold']))\n",
        "print(cl('Accuracy score of the Decision Tree Model is {}'.format(accuracy_score(y_test, tree_yhat)), attrs= ['bold']))\n",
        "print(cl('------------------------------------------------------------------------', attrs = ['bold']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mACCURACY SCORE\u001b[0m\n",
            "\u001b[1m------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[1mAccuracy score of the Decision Tree Model is 0.9993679997191109\u001b[0m\n",
            "\u001b[1m------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwhmZ7cGvHLP"
      },
      "source": [
        "#Models\n",
        "\n",
        "#2. K-Nearest Neighbors\n",
        "\n",
        "n = 5\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors = n)\n",
        "knn.fit(X_train, y_train)\n",
        "knn_yhat = knn.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeZ-gYiSmceo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cef892c-751c-4d9f-83e9-a2fff7e9a3e7"
      },
      "source": [
        "#Evaluation Metrics from this metric\n",
        "\n",
        "print(cl('Accuracy score of the KNN model is {}'.format(accuracy_score(y_test, knn_yhat)), attrs = ['bold'], color = 'green'))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[32mAccuracy score of the KNN model is 0.9995259997893332\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjYEeLJvijxU"
      },
      "source": [
        "#Models\n",
        "\n",
        "#3. Logistic Regression\n",
        "\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "lr_yhat = lr.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FScfqVOri3P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9295b27-5148-4f45-ed18-81731d5a2054"
      },
      "source": [
        "print(cl('Accuracy score of the Logistic Regression model is {}'.format(accuracy_score(y_test, lr_yhat)), attrs= ['bold']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mAccuracy score of the Logistic Regression model is 0.9991924440855307\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWbT0coeYOV2"
      },
      "source": [
        "#Models\n",
        "\n",
        "#4. SVM\n",
        "\n",
        "svm = SVC()\n",
        "svm.fit(X_train, y_train)\n",
        "svm_yhat = svm.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xj3Dn3ffY03c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adbc00b2-7e68-4e9b-898d-9c04b1fe87bc"
      },
      "source": [
        "print(cl('Accuracy score of the SVM model is{}'.format(accuracy_score(y_test, svm_yhat)), attrs = ['bold']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mAccuracy score of the SVM model is0.9993153330290369\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZEfbyXJsjXj"
      },
      "source": [
        "#Models\n",
        "\n",
        "#5. Random Forest Tree\n",
        "\n",
        "rf = RandomForestClassifier(max_depth = 4)\n",
        "rf.fit(X_train, y_train)\n",
        "rf_yhat = rf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OT0eK3wFtP9h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7c3e14d-0edc-4c71-f56c-c5dd18bd4bf2"
      },
      "source": [
        "print(cl('Accuracy score of the Random Forest Tree model is {}'.format(accuracy_score(y_test, rf_yhat)), attrs = ['bold']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mAccuracy score of the Random Forest Tree model is 0.9992802219023208\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se-Hssk4yZSG"
      },
      "source": [
        " #Models\n",
        "\n",
        " #6. XGBoost\n",
        "\n",
        " xgb = XGBClassifier(max_depth = 4)\n",
        " xgb.fit(X_train, y_train)\n",
        " xgb_yhat = xgb.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqQ9lbdt1o3g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fb71052-f14d-48bd-e08a-42906ef1459b"
      },
      "source": [
        "print(cl('Accuracy score of the XGBoost model is {}'.format(accuracy_score(y_test, xgb_yhat)), attrs = ['bold']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mAccuracy score of the XGBoost model is 0.9994733330992591\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id9euagE1_kM"
      },
      "source": [
        "The model with the least accuracy score is the Logistic Regression model whereas the model with the highest accuracy score is the KNN.\n",
        "\n",
        "Another accuracy metric widely used in evaluating models is the f1 score. You calculate it by dividing the product F1 score = 2((precision * recall) / (precision + recall))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMV7Z3gx2T71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edbb22a6-4634-4545-8ef6-0f7e8fe3725c"
      },
      "source": [
        "# 2. F1 scores\n",
        "\n",
        "print(cl('F1 SCORES', attrs = ['bold']))\n",
        "\n",
        "print(cl('F1 score of the Decision Tree model is {}'.format(f1_score(y_test, tree_yhat)), attrs = ['bold']))\n",
        "print(cl('F1 score of the KNN model is {}'.format(f1_score(y_test, knn_yhat)), attrs = ['bold'], color = 'green'))\n",
        "print(cl('F1 score of the Logistic Regression model is {}'.format(f1_score(y_test, lr_yhat)), attrs = ['bold'], color = 'red'))\n",
        "print(cl('F1 score of the SVM model is {}'.format(f1_score(y_test, svm_yhat)), attrs = ['bold']))\n",
        "print(cl('F1 score of the Random Forest Tree model is {}'.format(f1_score(y_test, rf_yhat)), attrs = ['bold']))\n",
        "print(cl('F1 score of the XGBoost model is {}'.format(f1_score(y_test, xgb_yhat)), attrs = ['bold']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mF1 SCORES\u001b[0m\n",
            "\u001b[1mF1 score of the Decision Tree model is 0.8105263157894738\u001b[0m\n",
            "\u001b[1m\u001b[32mF1 score of the KNN model is 0.8571428571428572\u001b[0m\n",
            "\u001b[1m\u001b[31mF1 score of the Logistic Regression model is 0.7356321839080459\u001b[0m\n",
            "\u001b[1mF1 score of the SVM model is 0.7771428571428572\u001b[0m\n",
            "\u001b[1mF1 score of the Random Forest Tree model is 0.768361581920904\u001b[0m\n",
            "\u001b[1mF1 score of the XGBoost model is 0.8421052631578948\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNKRyoLDlh_e"
      },
      "source": [
        "# **Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-VBT5p-lcDb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "18bbbc0e-33ca-4f64-ed70-561232451989"
      },
      "source": [
        "#3. Confusion Matrix\n",
        "\n",
        "#defining the plot function\n",
        "\n",
        "#Everything works perfectly and the code below creates a confusion matrix for each of the classification models\n",
        "#You can see those on the files tab or download them as a png file to see.\n",
        "#for some reason each picture it creates is blank. I need to fix this.\n",
        "\n",
        "def plot_confusion_matrix(cm, classes, title, normalize = False, cmap = plt.cm.Blues):\n",
        "  title = 'Confusion Matrix of {}'.format(title)\n",
        "  if normalize:\n",
        "    cm = cm.astype(float) / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n",
        "    #cmap stands for color map and it's part of a library. Matplotlib?\n",
        "    plt.title(title) #plt is the pyplot package that we imported at the beginning of our code.\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation = 45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "      plt.text(j, i, format(cm[i, j], fmt),\n",
        "               horizontalalignment = 'center',\n",
        "               color = 'white' if cm[i, j] > thresh else 'black')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "#Now that we have the code above we are going to compute the confusion matrix for each of the classification models.\n",
        "\n",
        "tree_matrix = confusion_matrix(y_test, tree_yhat, labels = [0, 1]) # Decision Tree\n",
        "knn_matrix = confusion_matrix(y_test, knn_yhat, labels = [0, 1]) #K-Nearest Neighbors\n",
        "lr_matrix = confusion_matrix(y_test, lr_yhat, labels = [0, 1]) #Logistic Regression\n",
        "svm_matrix = confusion_matrix(y_test, svm_yhat, labels = [0, 1]) #Support Vector Machine\n",
        "rf_matrix = confusion_matrix(y_test, rf_yhat, labels = [0, 1]) #Random Forest Tree\n",
        "xgb_matrix = confusion_matrix(y_test, xgb_yhat, labels = [0, 1]) #XGBoost\n",
        "\n",
        "#Plot each confusion matrix\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (6,6)\n",
        "\n",
        "#1. Decision tree\n",
        "\n",
        "tree_cm_plot = plot_confusion_matrix(tree_matrix,\n",
        "                                     classes = ['Non-Default(0)', 'Default(1)'],\n",
        "                                     normalize = False, title = 'Decision Tree')\n",
        "plt.savefig('tree_cm_plot.png')\n",
        "plt.show()\n",
        "\n",
        "#2. K-Nearest Neighbors\n",
        "\n",
        "knn_cm_plot = plot_confusion_matrix(knn_matrix,\n",
        "                                    classes = ['Non-Default(0)', 'Default(1)'],\n",
        "                                    normalize = False, title = 'KNN')\n",
        "plt.savefig('knn_cm_plot.png')\n",
        "plt.show()\n",
        "\n",
        "#3. Logistic Regression\n",
        "\n",
        "lr_cm_plot = plot_confusion_matrix(lr_matrix,\n",
        "                                   classes = ['Non-Default(0)', 'Default(1)'],\n",
        "                                   normalize = False, title = 'Logistic Regression')\n",
        "plt.savefig('lr_cm_plot.png')\n",
        "plt.show()\n",
        "\n",
        "#4. Support Vector Machine\n",
        "\n",
        "svm_cm_plot = plot_confusion_matrix(svm_matrix,\n",
        "                                    classes = ['Non-Default(0)', 'Default(1)'],\n",
        "                                    normalize = False, title = 'SVM')\n",
        "plt.savefig('svm_cm_plot.png')\n",
        "plt.show()\n",
        "\n",
        "#5. Random Forest Tree\n",
        "\n",
        "rf_cm_plot = plot_confusion_matrix(rf_matrix,\n",
        "                                   classes = ['Non-Default(0)', 'Default(1)'],\n",
        "                                   normalize = False, title = 'Random Forest Tree')\n",
        "plt.savefig('rf_cm_plot.png')\n",
        "plt.show()\n",
        "\n",
        "#6. XGBoost\n",
        "\n",
        "xgb_cm_plot = plot_confusion_matrix(xgb_matrix,\n",
        "                                    classes = ['Non-Default(0)', 'Default(1)'],\n",
        "                                    normalize = False, title = 'XGBoost')\n",
        "plt.savefig('xgb_cm_plot.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x432 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x432 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x432 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x432 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x432 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x432 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}