{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Credit Card Fraud Detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "QXBU-HzC9ddd"
   },
   "source": [
    "#STEP 1: IMPORTING PACKAGES\n",
    "\n",
    "import pandas as pd # this package is for data processing\n",
    "import numpy as np #library to work with arrays\n",
    "import matplotlib.pyplot as plt #library to create visualizations in Python\n",
    "import tensorflow as tf #TensorFlow\n",
    "from termcolor import colored as cl #tool for text customization\n",
    "import itertools #library in Python consisting of multiple methods used in iterators\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler #Tool for data normalization/standardization\n",
    "from sklearn.model_selection import train_test_split #function that splits data arrays into 2 subsets: training & testing\n",
    "from sklearn.tree import DecisionTreeClassifier #Decision tree algorithm\n",
    "from sklearn.neighbors import KNeighborsClassifier #algorithm that implements learning based on the k nearest neighbors\n",
    "from sklearn.linear_model import LogisticRegression #Logistic regression algorithm (ML algorithm used to predict the probability of a categorical dependent variable)\n",
    "from sklearn.svm import SVC #Stands for \"Support Vector Classification\", and it's an SVM algorithm\n",
    "from sklearn.ensemble import RandomForestClassifier #Random forest tree algorithm\n",
    "from xgboost import XGBClassifier #Machine Learning Algorithm.\n",
    "\n",
    "from sklearn.metrics import confusion_matrix #evaluation metric\n",
    "from sklearn.metrics import accuracy_score #evaluation metric\n",
    "from sklearn.metrics import f1_score #evaluation metric"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "17925EC49_Ez"
   },
   "source": [
    "**Notes:**\n",
    "- Iterators are objects that allow us to iterate over all the elements of a collection and return one element at a time.\n",
    "- When a dataset contains variable that are in different scales, *StandardScaler* performs the task of **Standardization** so they have a common scale.\n",
    "- **Support Vector Machines** are supervised learning methods used for classification.\n",
    "- **Random Forest Classifier** creates a set of decision trees from a random subset of the training set.\n",
    "- **XGBoost** is an implementation of gradient boosted decision trees designed for speed and performance.\n",
    "- A **Confusion Matrix** is a summary of prediction results on a classification problem.\n",
    "- Accuracy is simply a ratio of correctly predicted observations to the total observations.\n",
    "- Also known as F-score, the **F1 Score** is a weighted average of the precision and recall score. Used as an evaluation metric, a high F-score is a sign of a well-performing model."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "ok": true,
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "status": 200,
       "status_text": ""
      }
     },
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "id": "ougfKzMR-EHZ",
    "outputId": "5c5b212f-3f48-4f67-878b-68e4797ce0c9"
   },
   "source": [
    "#Now I'm going to import my data from the Kaggle dataset which I have previously downloaded to my computer from\n",
    "#the following website:\n",
    "\n",
    "#kaggle dataset: https://www.kaggle.com/mlg-ulb/creditcardfraud\n",
    "\n",
    "\n",
    "from google.colab import files #On Nov 28 I introduced these two lines of code and it was one of the best decisions.\n",
    "uploaded = files.upload() #This creates a widget prompting the user to browse for a file and uploads it to files inside Colab.\n",
    "df = pd.read_csv('../../Downloads/creditcard.csv')\n",
    "df.drop('Time', axis = 1, inplace = True)\n",
    "df.head"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-2a66b45e-7577-48c8-bc92-20356eb6a91a\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-2a66b45e-7577-48c8-bc92-20356eb6a91a\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saving creditcard.csv to creditcard (2).csv\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                V1         V2        V3  ...       V28  Amount  Class\n",
       "0       -1.359807  -0.072781  2.536347  ... -0.021053  149.62      0\n",
       "1        1.191857   0.266151  0.166480  ...  0.014724    2.69      0\n",
       "2       -1.358354  -1.340163  1.773209  ... -0.059752  378.66      0\n",
       "3       -0.966272  -0.185226  1.792993  ...  0.061458  123.50      0\n",
       "4       -1.158233   0.877737  1.548718  ...  0.215153   69.99      0\n",
       "...           ...        ...       ...  ...       ...     ...    ...\n",
       "284802 -11.881118  10.071785 -9.834783  ...  0.823731    0.77      0\n",
       "284803  -0.732789  -0.055080  2.035030  ... -0.053527   24.79      0\n",
       "284804   1.919565  -0.301254 -3.249640  ... -0.026561   67.88      0\n",
       "284805  -0.240440   0.530483  0.702510  ...  0.104533   10.00      0\n",
       "284806  -0.533413  -0.189733  0.703337  ...  0.013649  217.00      0\n",
       "\n",
       "[284807 rows x 30 columns]>"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7jQRiwaRXKqG",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "24626e8e-20fa-4b79-db99-56f13416b2f1"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QHfDAc-X7oiV",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ac874ef9-3b58-4585-efe7-aa47d6f5bf80"
   },
   "source": [
    "cases = len(df)\n",
    "nonfraud_count = len(df[df.Class == 0])\n",
    "fraud_count = len(df[df.Class == 1])\n",
    "fraud_percentage = round(fraud_count/nonfraud_count*100, 2)\n",
    "\n",
    "print(cl('CASE COUNT', attrs = ['bold']))\n",
    "print(cl('--------------------------------------------------', attrs= ['bold']))\n",
    "print(cl('Total number of cases are {}'.format(cases), attrs = ['bold']))\n",
    "print(cl('Number of Non-fraud cases are {}'.format(nonfraud_count), attrs = ['bold']))\n",
    "print(cl('Percentage of fraud cases is {}'.format(fraud_percentage), attrs = ['bold']))\n",
    "print(cl('--------------------------------------------------', attrs = ['bold']))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[1mCASE COUNT\u001B[0m\n",
      "\u001B[1m--------------------------------------------------\u001B[0m\n",
      "\u001B[1mTotal number of cases are 284807\u001B[0m\n",
      "\u001B[1mNumber of Non-fraud cases are 284315\u001B[0m\n",
      "\u001B[1mPercentage of fraud cases is 0.17\u001B[0m\n",
      "\u001B[1m--------------------------------------------------\u001B[0m\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5kH31BA4n31g"
   },
   "source": [
    "**Notes:**\n",
    "- When working with the **print statement** I am wondering... *What does the \"cl\" stand for?*"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "W3G8VpVzptYN",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "076703ba-f8fb-4702-c339-0e94370dd925"
   },
   "source": [
    "nonfraud_cases = df[df.Class == 0]\n",
    "fraud_cases = df[df.Class == 1]\n",
    "\n",
    "#What are we doing here? Are we creating a class or some sort\n",
    "#of boolean?\n",
    "\n",
    "print(cl('CASE AMOUNT STATISTICS', attrs = ['bold']))\n",
    "print(cl('--------------------------------------------------', attrs= ['bold']))\n",
    "print(cl('NON-FRAUD CASE AMOUNT STATS', attrs= ['bold']))\n",
    "print(nonfraud_cases.Amount.describe())\n",
    "print(cl('--------------------------------------------------', attrs= ['bold']))\n",
    "print(cl('FRAUD CASE AMOUNT STATS', attrs= ['bold']))\n",
    "print(fraud_cases.Amount.describe())\n",
    "print(cl('--------------------------------------------------', attrs= ['bold']))\n",
    "\n",
    "#I think what this is doing is to call the describe function\n",
    "#with amounts. But what does *.amount* do?"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[1mCASE AMOUNT STATISTICS\u001B[0m\n",
      "\u001B[1m--------------------------------------------------\u001B[0m\n",
      "\u001B[1mNON-FRAUD CASE AMOUNT STATS\u001B[0m\n",
      "count    284315.000000\n",
      "mean         88.291022\n",
      "std         250.105092\n",
      "min           0.000000\n",
      "25%           5.650000\n",
      "50%          22.000000\n",
      "75%          77.050000\n",
      "max       25691.160000\n",
      "Name: Amount, dtype: float64\n",
      "\u001B[1m--------------------------------------------------\u001B[0m\n",
      "\u001B[1mFRAUD CASE AMOUNT STATS\u001B[0m\n",
      "count     492.000000\n",
      "mean      122.211321\n",
      "std       256.683288\n",
      "min         0.000000\n",
      "25%         1.000000\n",
      "50%         9.250000\n",
      "75%       105.890000\n",
      "max      2125.870000\n",
      "Name: Amount, dtype: float64\n",
      "\u001B[1m--------------------------------------------------\u001B[0m\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eUT5RwQ6tiqM",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6bd7d2a8-0965-42ff-f74b-7862117f4543"
   },
   "source": [
    "#Now we are going to normalize our data because we need to\n",
    "#reduce the wide range of values in the \"Amount\" variable to\n",
    "#a smaller scale so we can work better.\n",
    "\n",
    "sc = StandardScaler()\n",
    "amount = df['Amount'].values\n",
    "\n",
    "df['Amount'] = sc.fit_transform(amount.reshape(-1, 1))\n",
    "\n",
    "print(cl(df['Amount'].head(10), attrs = ['bold']))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[1m0    0.244964\n",
      "1   -0.342475\n",
      "2    1.160686\n",
      "3    0.140534\n",
      "4   -0.073403\n",
      "5   -0.338556\n",
      "6   -0.333279\n",
      "7   -0.190107\n",
      "8    0.019392\n",
      "9   -0.338516\n",
      "Name: Amount, dtype: float64\u001B[0m\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HRmzsIfhCzOb",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "0ad4f248-246a-4c6b-a1b0-95dbf368b4b1"
   },
   "source": [
    "# DATA SPLIT\n",
    "#Defining the independent and dependent variables.\n",
    "\n",
    "X = df.drop('Class', axis = 1).values\n",
    "y = df['Class'].values\n",
    "\n",
    "#What does this line of code below mean?\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print(cl('X_train samples : ', attrs= ['bold']), X_train[:1])\n",
    "print(cl('X_test samples : ', attrs= ['bold']), X_test[0:1])\n",
    "print(cl('y_train samples : ', attrs=['bold']), y_train[0:20])\n",
    "print(cl('y_test samples: ', attrs = ['bold']), y_test[0:20])"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[1mX_train samples : \u001B[0m [[-1.11504743  1.03558276  0.80071244 -1.06039825  0.03262117  0.85342216\n",
      "  -0.61424348 -3.23116112  1.53994798 -0.81690879 -1.30559201  0.1081772\n",
      "  -0.85960958 -0.07193421  0.90665563 -1.72092961  0.79785322 -0.0067594\n",
      "   1.95677806 -0.64489556  3.02038533 -0.53961798  0.03315649 -0.77494577\n",
      "   0.10586781 -0.43085348  0.22973694 -0.0705913  -0.30145418]]\n",
      "\u001B[1mX_test samples : \u001B[0m [[-0.32333357  1.05745525 -0.04834115 -0.60720431  1.25982115 -0.09176072\n",
      "   1.1591015  -0.12433461 -0.17463954 -1.64440065 -1.11886302  0.20264731\n",
      "   1.14596495 -1.80235956 -0.24717793 -0.06094535  0.84660574  0.37945439\n",
      "   0.84726224  0.18640942 -0.20709827 -0.43389027 -0.26161328 -0.04665061\n",
      "   0.2115123   0.00829721  0.10849443  0.16113917 -0.19330595]]\n",
      "\u001B[1my_train samples : \u001B[0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001B[1my_test samples: \u001B[0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzNlL5s7E3am"
   },
   "source": [
    "We have all the required components to build our classification models, which is our next step.\n",
    "\n",
    "# **Building the Model**\n",
    "\n",
    "For this project we will build 6 different types of classification models using algorithms by scikit-learn.\n",
    "\n",
    "1. Decision Tree\n",
    "2. K-Nearest Neighbors (KNN)\n",
    "3. Logistic Regression\n",
    "4. Support Vector Machine (SVM)\n",
    "5. Random Forest\n",
    "6. XGBoost\n",
    "\n",
    "# **Evaluation Metrics for Classification Models**\n",
    "\n",
    "We will use the following metrics to evaluate the models and decide which one is the best#\n",
    "\n",
    "+ Accuracy Score\n",
    "+ F1 Score\n",
    "+ Confusion Matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NUNPbgFctThU"
   },
   "source": [
    "# Models\n",
    "\n",
    "# 1. Decision Tree\n",
    "\n",
    "#When max_depth = 4 we allow the tree to split four times\n",
    "#Criterion is a parameter that measures the quality of a split\n",
    "#in our decision trees. \"Gini Index\" & \"Entropy\" are two\n",
    "#different measures of impurity or disorder*?\n",
    "tree_model = DecisionTreeClassifier(max_depth = 4, criterion = 'entropy')\n",
    "tree_model.fit(X_train, y_train)\n",
    "tree_yhat = tree_model.predict(X_test)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "i55Ts6EeyTdi",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1c98e6b5-f3a8-4a1a-ecd3-9986b6968187"
   },
   "source": [
    "#Let's print the evaluation metrics for this model.\n",
    "\n",
    "# 1. Accuracy score\n",
    "\n",
    "print(cl('ACCURACY SCORE', attrs = ['bold']))\n",
    "print(cl('------------------------------------------------------------------------', attrs = ['bold']))\n",
    "print(cl('Accuracy score of the Decision Tree Model is {}'.format(accuracy_score(y_test, tree_yhat)), attrs= ['bold']))\n",
    "print(cl('------------------------------------------------------------------------', attrs = ['bold']))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[1mACCURACY SCORE\u001B[0m\n",
      "\u001B[1m------------------------------------------------------------------------\u001B[0m\n",
      "\u001B[1mAccuracy score of the Decision Tree Model is 0.9993679997191109\u001B[0m\n",
      "\u001B[1m------------------------------------------------------------------------\u001B[0m\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NwhmZ7cGvHLP"
   },
   "source": [
    "#Models\n",
    "\n",
    "#2. K-Nearest Neighbors\n",
    "\n",
    "n = 5\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = n)\n",
    "knn.fit(X_train, y_train)\n",
    "knn_yhat = knn.predict(X_test)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BeZ-gYiSmceo",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3cef892c-751c-4d9f-83e9-a2fff7e9a3e7"
   },
   "source": [
    "#Evaluation Metrics from this metric\n",
    "\n",
    "print(cl('Accuracy score of the KNN model is {}'.format(accuracy_score(y_test, knn_yhat)), attrs = ['bold'], color = 'green'))\n"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[1m\u001B[32mAccuracy score of the KNN model is 0.9995259997893332\u001B[0m\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MjYEeLJvijxU"
   },
   "source": [
    "#Models\n",
    "\n",
    "#3. Logistic Regression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_yhat = lr.predict(X_test)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2FScfqVOri3P",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f9295b27-5148-4f45-ed18-81731d5a2054"
   },
   "source": [
    "print(cl('Accuracy score of the Logistic Regression model is {}'.format(accuracy_score(y_test, lr_yhat)), attrs= ['bold']))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[1mAccuracy score of the Logistic Regression model is 0.9991924440855307\u001B[0m\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MWbT0coeYOV2"
   },
   "source": [
    "#Models\n",
    "\n",
    "#4. SVM\n",
    "\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "svm_yhat = svm.predict(X_test)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Xj3Dn3ffY03c",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "adbc00b2-7e68-4e9b-898d-9c04b1fe87bc"
   },
   "source": [
    "print(cl('Accuracy score of the SVM model is{}'.format(accuracy_score(y_test, svm_yhat)), attrs = ['bold']))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[1mAccuracy score of the SVM model is0.9993153330290369\u001B[0m\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4ZEfbyXJsjXj"
   },
   "source": [
    "#Models\n",
    "\n",
    "#5. Random Forest Tree\n",
    "\n",
    "rf = RandomForestClassifier(max_depth = 4)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_yhat = rf.predict(X_test)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OT0eK3wFtP9h",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a7c3e14d-0edc-4c71-f56c-c5dd18bd4bf2"
   },
   "source": [
    "print(cl('Accuracy score of the Random Forest Tree model is {}'.format(accuracy_score(y_test, rf_yhat)), attrs = ['bold']))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[1mAccuracy score of the Random Forest Tree model is 0.9992802219023208\u001B[0m\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "se-Hssk4yZSG"
   },
   "source": [
    " #Models\n",
    "\n",
    " #6. XGBoost\n",
    "\n",
    " xgb = XGBClassifier(max_depth = 4)\n",
    " xgb.fit(X_train, y_train)\n",
    " xgb_yhat = xgb.predict(X_test)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IqQ9lbdt1o3g",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6fb71052-f14d-48bd-e08a-42906ef1459b"
   },
   "source": [
    "print(cl('Accuracy score of the XGBoost model is {}'.format(accuracy_score(y_test, xgb_yhat)), attrs = ['bold']))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[1mAccuracy score of the XGBoost model is 0.9994733330992591\u001B[0m\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "id9euagE1_kM"
   },
   "source": [
    "The model with the least accuracy score is the Logistic Regression model whereas the model with the highest accuracy score is the KNN.\n",
    "\n",
    "Another accuracy metric widely used in evaluating models is the f1 score. You calculate it by dividing the product F1 score = 2((precision * recall) / (precision + recall))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IMV7Z3gx2T71",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "edbb22a6-4634-4545-8ef6-0f7e8fe3725c"
   },
   "source": [
    "# 2. F1 scores\n",
    "\n",
    "print(cl('F1 SCORES', attrs = ['bold']))\n",
    "\n",
    "print(cl('F1 score of the Decision Tree model is {}'.format(f1_score(y_test, tree_yhat)), attrs = ['bold']))\n",
    "print(cl('F1 score of the KNN model is {}'.format(f1_score(y_test, knn_yhat)), attrs = ['bold'], color = 'green'))\n",
    "print(cl('F1 score of the Logistic Regression model is {}'.format(f1_score(y_test, lr_yhat)), attrs = ['bold'], color = 'red'))\n",
    "print(cl('F1 score of the SVM model is {}'.format(f1_score(y_test, svm_yhat)), attrs = ['bold']))\n",
    "print(cl('F1 score of the Random Forest Tree model is {}'.format(f1_score(y_test, rf_yhat)), attrs = ['bold']))\n",
    "print(cl('F1 score of the XGBoost model is {}'.format(f1_score(y_test, xgb_yhat)), attrs = ['bold']))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[1mF1 SCORES\u001B[0m\n",
      "\u001B[1mF1 score of the Decision Tree model is 0.8105263157894738\u001B[0m\n",
      "\u001B[1m\u001B[32mF1 score of the KNN model is 0.8571428571428572\u001B[0m\n",
      "\u001B[1m\u001B[31mF1 score of the Logistic Regression model is 0.7356321839080459\u001B[0m\n",
      "\u001B[1mF1 score of the SVM model is 0.7771428571428572\u001B[0m\n",
      "\u001B[1mF1 score of the Random Forest Tree model is 0.768361581920904\u001B[0m\n",
      "\u001B[1mF1 score of the XGBoost model is 0.8421052631578948\u001B[0m\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNKRyoLDlh_e"
   },
   "source": [
    "# **Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "t-VBT5p-lcDb",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "outputId": "18bbbc0e-33ca-4f64-ed70-561232451989"
   },
   "source": [
    "#3. Confusion Matrix\n",
    "\n",
    "#defining the plot function\n",
    "\n",
    "#Everything works perfectly and the code below creates a confusion matrix for each of the classification models\n",
    "#You can see those on the files tab or download them as a png file to see.\n",
    "#for some reason each picture it creates is blank. I need to fix this.\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, title, normalize = False, cmap = plt.cm.Blues):\n",
    "  title = 'Confusion Matrix of {}'.format(title)\n",
    "  if normalize:\n",
    "    cm = cm.astype(float) / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n",
    "    #cmap stands for color map and it's part of a library. Matplotlib?\n",
    "    plt.title(title) #plt is the pyplot package that we imported at the beginning of our code.\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation = 45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "      plt.text(j, i, format(cm[i, j], fmt),\n",
    "               horizontalalignment = 'center',\n",
    "               color = 'white' if cm[i, j] > thresh else 'black')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "#Now that we have the code above we are going to compute the confusion matrix for each of the classification models.\n",
    "\n",
    "tree_matrix = confusion_matrix(y_test, tree_yhat, labels = [0, 1]) # Decision Tree\n",
    "knn_matrix = confusion_matrix(y_test, knn_yhat, labels = [0, 1]) #K-Nearest Neighbors\n",
    "lr_matrix = confusion_matrix(y_test, lr_yhat, labels = [0, 1]) #Logistic Regression\n",
    "svm_matrix = confusion_matrix(y_test, svm_yhat, labels = [0, 1]) #Support Vector Machine\n",
    "rf_matrix = confusion_matrix(y_test, rf_yhat, labels = [0, 1]) #Random Forest Tree\n",
    "xgb_matrix = confusion_matrix(y_test, xgb_yhat, labels = [0, 1]) #XGBoost\n",
    "\n",
    "#Plot each confusion matrix\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (6,6)\n",
    "\n",
    "#1. Decision tree\n",
    "\n",
    "tree_cm_plot = plot_confusion_matrix(tree_matrix,\n",
    "                                     classes = ['Non-Default(0)', 'Default(1)'],\n",
    "                                     normalize = False, title = 'Decision Tree')\n",
    "plt.savefig('tree_cm_plot.png')\n",
    "plt.show()\n",
    "\n",
    "#2. K-Nearest Neighbors\n",
    "\n",
    "knn_cm_plot = plot_confusion_matrix(knn_matrix,\n",
    "                                    classes = ['Non-Default(0)', 'Default(1)'],\n",
    "                                    normalize = False, title = 'KNN')\n",
    "plt.savefig('knn_cm_plot.png')\n",
    "plt.show()\n",
    "\n",
    "#3. Logistic Regression\n",
    "\n",
    "lr_cm_plot = plot_confusion_matrix(lr_matrix,\n",
    "                                   classes = ['Non-Default(0)', 'Default(1)'],\n",
    "                                   normalize = False, title = 'Logistic Regression')\n",
    "plt.savefig('lr_cm_plot.png')\n",
    "plt.show()\n",
    "\n",
    "#4. Support Vector Machine\n",
    "\n",
    "svm_cm_plot = plot_confusion_matrix(svm_matrix,\n",
    "                                    classes = ['Non-Default(0)', 'Default(1)'],\n",
    "                                    normalize = False, title = 'SVM')\n",
    "plt.savefig('svm_cm_plot.png')\n",
    "plt.show()\n",
    "\n",
    "#5. Random Forest Tree\n",
    "\n",
    "rf_cm_plot = plot_confusion_matrix(rf_matrix,\n",
    "                                   classes = ['Non-Default(0)', 'Default(1)'],\n",
    "                                   normalize = False, title = 'Random Forest Tree')\n",
    "plt.savefig('rf_cm_plot.png')\n",
    "plt.show()\n",
    "\n",
    "#6. XGBoost\n",
    "\n",
    "xgb_cm_plot = plot_confusion_matrix(xgb_matrix,\n",
    "                                    classes = ['Non-Default(0)', 'Default(1)'],\n",
    "                                    normalize = False, title = 'XGBoost')\n",
    "plt.savefig('xgb_cm_plot.png')\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {}
    }
   ]
  }
 ]
}
